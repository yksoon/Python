{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitmlpythoncondab440e4a2d64a43fabfdb626079ecdf20",
   "display_name": "Python 3.7.6 64-bit ('ml_python': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q. Titanic 생존자 예측 모델 성능을 개선하고자 아래와 같이 교차 검증 및 하이퍼 파라미터 튜닝을 수행하세요.\n",
    " - KFold 교차검증(랜덤포레스트 적용)\n",
    " - cross_val_score를 활용한 교차 검증(랜덤 포레스트 적용)\n",
    " - GridSearchCV를 활용한 교차 검증과 최적 하이퍼파라미터 수행하고 성능을 평가\n",
    "   - RandomForestClassifier의 최적 하이퍼 파라미터를 찾고 예측 성능 측정 parameters = {'n_estimators':[50,100,200],'max_depth':[2,3,5],'min_samples_leaf':[1,5,8]}\n",
    "   - LogisticRegression의 최적 하이퍼 파라미터를 찾고 예측 성능 측정 parameters = {'penalty':['l2','l1'],'C':[0.01,0.1,1,1,5,10]}\n",
    " \n",
    "#### RF 파라미터\n",
    " - n_estimators : (나무의 개수)랜덤 포레스트에서 결정 트리의 개수를 지정. 디폴트는 10개\n",
    "    - 많이 설정할 수록 좋은 성능을 기대할 수  있지만 학습 수행시간이 오래 걸림\n",
    " - max_features : 결정 트리에 사용된 max_features 파라미터와 같음. sqrt(전체 피처 개수)만큼 참조. 피터가 16개라면 분할 위해 4개 참조\n",
    " \n",
    "#### LR 파라미터\n",
    "    - (과재적합을 피하기 위해 회귀계수를 조정해야하는데, 조정하는 방식을 말한다.)\n",
    " - L1 : 불필요한 회귀계수를 급격하게 감소시켜 0으로 만들고 제거\n",
    " - L2 : 회귀 계수의 크기를 감소시킴\n",
    " - C : 규제 강도를 조절하는 alpha 값의 역수. 즉 C값이 작을 수록 규제 강도가 큼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "교차 검증 0정확도: 0.7710\n교차 검증 1정확도: 0.8473\n교차 검증 2정확도: 0.7405\n교차 검증 3정확도: 0.6947\n교차 검증 4정확도: 0.7816\n평균 정확도:  0.7670\n"
    }
   ],
   "source": [
    "# 독립변수, 종속변수 분리\n",
    "t_df = pd.read_pickle('t_df.pkl')\n",
    "\n",
    "y_df = t_df.survived\n",
    "X_df = t_df.drop('survived', axis=1)\n",
    "\n",
    "# 학습용 평가용 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=11)\n",
    "\n",
    "# 분류기 객체 생성\n",
    "# dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "# lr_clf = LogisticRegression(random_state=11)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# KFold 교차 검증 수행()\n",
    "# K개의 데이터 폴드 세트를 만들어서 K번 만큼 각 폴드 세트에\n",
    "# 학습과 검증 평가를 반복, K가 5이면 5번 평가를 평균한 결과로 예측 성능 검증\n",
    "# 예측 성능 평가\n",
    "def exec_kfold(clf, folds=5):      # clf는 클래시파이어, folds는 k의 개수\n",
    "    kfold = KFold(n_splits=folds)  # n_splits = folds\n",
    "    scores = []                    # 만들어서 저장하는 공간( foltset 설정하는 단계 )\n",
    "    \n",
    "    for iter_count, (train_index, test_index) \\\n",
    "    in enumerate(kfold.split(X_df)):            # enumerate 해서 독립변수 쪽의 5개를 하나씩 작업해준다.\n",
    "        X_train, X_test = X_df.values[train_index], X_df.values[test_index]\n",
    "        y_train, y_test = y_df.values[train_index], y_df.values[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train)                    # 반복학습 ( 이 작업들을 각 fold마다 진행 )\n",
    "        predictions = clf.predict(X_test)            # 예측값 삽입 \n",
    "        accuracy = accuracy_score(y_test, predictions) # 각 폴드마다 한 것을 append 해준다.\n",
    "        scores.append(accuracy)                      # 5개에 대한 정확도를 출력\n",
    "        print('교차 검증 {0}정확도: {1:.4f}'.format(iter_count, accuracy))\n",
    "        # print('검증 세트 인덱스: {1}'.format(iter_count, test_index))\n",
    "        \n",
    "    mean_score = np.mean(scores)                   # mean_score로 평균을 구해준다.(5개 결과를 저장한 scores를 호출하여)\n",
    "    print('평균 정확도: {0: .4f}'.format(mean_score))\n",
    "        \n",
    "exec_kfold(rf_clf, folds=5)       # 5로 변경하면 5개가 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "교차 검증 0 정확도: 0.5573\n교차 검증 1 정확도: 0.8397\n교차 검증 2 정확도: 0.8092\n교차 검증 3 정확도: 0.7939\n교차 검증 4 정확도: 0.7710\n교차 검증 5 정확도: 0.8397\n교차 검증 6 정확도: 0.7099\n교차 검증 7 정확도: 0.6183\n교차 검증 8 정확도: 0.6565\n교차 검증 9 정확도: 0.6923\n평균 정확도:0.7288\n"
    }
   ],
   "source": [
    "# cross_val_scores\n",
    "# KFold의 일련의 과정을 한꺼번에 수행해주는 API\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf_clf, X_df, y_df, cv=10)        # cv=5는 교차검증을 얼마나 할 것인가, 숫자를 올리면 KFold와 비슷해진다.\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print('교차 검증 {0} 정확도: {1:.4f}'.format(iter_count, accuracy))\n",
    "    \n",
    "print('평균 정확도:{0:.4f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "GridSearchCV(cv=5, error_score=nan,\n             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                              class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features='auto',\n                                              max_leaf_nodes=None,\n                                              max_samples=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2,\n                                              min_weight_fraction_leaf=0.0,\n                                              n_estimators=100, n_jobs=None,\n                                              oob_score=False, random_state=11,\n                                              verbose=0, warm_start=False),\n             iid='deprecated', n_jobs=None,\n             param_grid={'max_depth': [2, 3, 5], 'min_samples_leaf': [1, 5, 8],\n                         'n_estimators': [50, 100, 200]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='accuracy', verbose=0)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 200}\nGridSearchCV 최고 정확도: 0.8042105263157895\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=5, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=11, verbose=0,\n                       warm_start=False)"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GSCV 예측 정확도 :  0.7977099236641222\n"
    }
   ],
   "source": [
    "t_df = pd.read_pickle('t_df.pkl')\n",
    "\n",
    "y_df = t_df.survived\n",
    "X_df = t_df.drop('survived', axis=1)\n",
    "\n",
    "# 학습용 평가용 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=11)\n",
    "\n",
    "# 분류기 객체 생성\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# GridSearchCV : 파라미터를 통해 성능을 튜닝. (타이타닉 생존률을 해결하기 위해 필요한 작업)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "parameters = {'n_estimators':[50,100,200],'max_depth':[2,3,5],'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(rf_clf, param_grid=parameters, scoring='accuracy', cv=5, refit=True) \n",
    "\n",
    "display(grid_dclf)\n",
    "grid_dclf.fit(X_train, y_train) \n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_dclf.best_params_) \n",
    "\n",
    "print('GridSearchCV 최고 정확도:', grid_dclf.best_score_) \n",
    "\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "display(best_dclf)\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print('GSCV 예측 정확도 : ', accuracy) "
   ]
  }
 ]
}